# Phase 2: Multi-LLM Debate Engine - Research Summary

**Research Date:** December 2-3, 2025
**Researcher:** Research Agent
**Status:** âœ… Complete

---

## Overview

This directory contains comprehensive research for implementing the Phase 2 Multi-LLM Debate Engine. Research covers four critical areas needed for production-ready implementation.

---

## Research Documents

### 1. XState Patterns ([xstate-patterns.md](./xstate-patterns.md))

**Key Findings:**
- âœ… 11-state FSM design with sub-states for debate lifecycle
- âœ… Actor-based parallel coordination for concurrent LLM calls
- âœ… Guard-driven format selection (free-form, structured, round-limited, convergence)
- âœ… Event-driven real-time updates for streaming
- âœ… Performance: <50ms overhead, negligible compared to LLM latency

**Recommendation:** XState v5 is optimal for debate orchestration.

**Implementation Priority:**
1. Core state machine (11 states)
2. Actor definitions for debaters/judge
3. Format guards
4. Parallel coordination
5. FastAPI integration

---

### 2. Parallel Streaming ([parallel-streaming.md](./parallel-streaming.md))

**Key Findings:**
- âœ… SSE handles 2-4 concurrent streams efficiently
- âœ… HTTP/2 multiplexing recommended for >4 streams
- âœ… Time-window buffering (100ms) for synchronized display
- âœ… Exponential backoff reconnection (1s base, 30s max)
- âœ… Graceful degradation when one stream fails

**Recommendation:** Use SSE with HTTP/2, synchronized buffering, isolated failure handling.

**Implementation Priority:**
1. Parallel SSE connection manager
2. Time-window buffering
3. Error detection and recovery
4. Exponential backoff reconnection
5. Last-Event-ID resumption

---

### 3. Context & Cost Management ([context-cost-management.md](./context-cost-management.md))

**Key Findings:**
- âœ… Hybrid sliding window + summarization strategy optimal
- âœ… Provider-specific token counting (Anthropic API, tiktoken for OpenAI)
- âœ… Real-time cost tracking with per-request updates
- âœ… Three-tier warning system ($0.50 yellow, $1.00 red, $2.00 critical)
- âœ… Typical 5-round debate: $0.08-$0.11 (very affordable)

**Recommendation:** Sliding window with last-n-rounds strategy, real-time cost tracking, user-configurable thresholds.

**Implementation Priority:**
1. Sliding window manager (last-n-rounds)
2. Unified token counter
3. Real-time cost tracking
4. Warning system ($0.50, $1.00, $2.00)
5. Cost projection and breakdown

---

### 4. Debate Coordination ([debate-coordination.md](./debate-coordination.md))

**Key Findings:**
- âœ… Hybrid coordination: Simultaneous for speed, turn-taking for depth
- âœ… LLM-powered auto-assignment generates diverse perspectives
- âœ… Six-dimensional judge rubric (logic, evidence, engagement, novelty, persuasiveness, relevance)
- âœ… Structured JSON output for consistent evaluation
- âœ… Stop criteria detection (repetition, drift, diminishing returns)

**Recommendation:** Hybrid coordination with simultaneous opening/closing and turn-taking rebuttals.

**Implementation Priority:**
1. Simultaneous coordinator
2. Turn-taking coordinator
3. Auto-assignment algorithm
4. Six-dimensional judge rubric
5. Stop criteria detection

---

## Architecture Synthesis

### Backend Architecture (FastAPI + XState)

```
FastAPI Endpoint
  â†“
  XState Actor Instance (Debate Machine)
  â†“
  Parallel LLM Calls (LiteLLM)
  â†“
  SSE Stream to Frontend
  â†“
  Real-time UI Updates
```

**Key Components:**
1. **Debate State Machine** (XState v5)
   - 11 states: CONFIGURING â†’ STARTING â†’ RUNNING â†’ JUDGING â†’ COMPLETED
   - Sub-states for round coordination
   - Format guards for debate types

2. **Parallel Stream Manager** (SSE)
   - HTTP/2 multiplexed connections
   - Time-window buffering (100ms)
   - Graceful error handling

3. **Context Manager** (Sliding Window)
   - Last-n-rounds strategy
   - Summarization fallback
   - Provider-specific token counting

4. **Cost Tracker** (Real-time)
   - Per-request tracking
   - Three-tier warnings
   - Provider/debater breakdown

5. **Coordination Engine** (Hybrid)
   - Simultaneous execution for parallel rounds
   - Turn-taking for sequential rounds
   - Phase-based strategy selection

6. **Judge System** (Structured Output)
   - Six-dimensional rubric
   - Stop criteria detection
   - Per-round assessments

---

## Performance Benchmarks

| Component | Latency | Bottleneck |
|-----------|---------|------------|
| XState transitions | <1ms | âŒ Not a bottleneck |
| SSE connection | 50-200ms | âŒ Not a bottleneck |
| Parallel coordination | 10-20ms | âŒ Not a bottleneck |
| Token counting | 0.5-2ms | âŒ Not a bottleneck |
| Cost calculation | <0.1ms | âŒ Not a bottleneck |
| **LLM API calls** | **2-10 seconds** | âœ… **Primary bottleneck** |
| Context compression | 0.5-2 seconds | âš ï¸ Secondary bottleneck |

**Conclusion:** System overhead is minimal (<100ms total). LLM generation speed is the primary constraint.

---

## Cost Analysis

**Typical 5-Round Debate:**
- 3 debaters (Claude Sonnet, GPT-4o, Gemini Flash)
- 1 judge (GPT-4o)
- 500 tokens/response average

**Estimated Cost:** $0.08-$0.11

**Warning Thresholds:**
- ðŸŸ¡ Yellow: $0.50 (caution, consider wrapping up)
- ðŸ”´ Red: $1.00 (confirm to continue)
- ðŸ›‘ Critical: $2.00 (auto-stop or override required)

---

## Implementation Roadmap

### Phase 2A: Core Engine (Weeks 1-2)
- [ ] XState debate state machine (11 states)
- [ ] Parallel SSE stream manager
- [ ] Basic sliding window context management
- [ ] Real-time cost tracking with warnings
- [ ] Simultaneous coordination
- [ ] Simple judge evaluation

**Deliverable:** Working multi-LLM debate with basic orchestration

### Phase 2B: Advanced Features (Weeks 3-4)
- [ ] Turn-taking coordination
- [ ] Hybrid coordination strategy
- [ ] Auto-assignment with diversity
- [ ] Full six-dimensional judge rubric
- [ ] Exponential backoff reconnection
- [ ] Context compression strategies

**Deliverable:** Production-ready debate engine with all formats

### Phase 2C: Optimization & Polish (Weeks 5-6)
- [ ] HTTP/2 optimization
- [ ] Last-Event-ID resumption
- [ ] Cost projection and breakdown
- [ ] Judge feedback UI
- [ ] Performance benchmarking
- [ ] Error recovery testing

**Deliverable:** Optimized, battle-tested debate engine

---

## Risk Mitigation

### High-Confidence (Low Risk)
- âœ… XState v5 maturity and performance
- âœ… SSE browser support and reliability
- âœ… Provider API stability

### Medium-Confidence (Manageable Risk)
- âš ï¸ Context compression quality (mitigation: user warnings)
- âš ï¸ Judge consistency (mitigation: structured output + temperature 0.3)
- âš ï¸ Cost overruns (mitigation: three-tier warnings with auto-stop)

### Mitigation Strategies
1. **Context Issues:** Implement sliding window + summarization fallback
2. **Judge Quality:** Use structured JSON output with strict schema
3. **Cost Control:** Real-time tracking with user-configurable limits
4. **Stream Failures:** Isolated error handling, continue with remaining debaters

---

## Technology Stack

**State Management:**
- XState v5 (state machine)
- Zustand (UI state, optional)

**Backend:**
- FastAPI (Python 3.11+)
- LiteLLM (multi-provider)
- tiktoken (token counting)

**Streaming:**
- SSE (Server-Sent Events)
- HTTP/2 (multiplexing)

**Frontend:**
- Next.js 15 + React 19
- EventSource API (SSE client)

---

## Key Metrics for Success

**Performance:**
- âœ… State transition latency: <1ms
- âœ… Parallel coordination overhead: <20ms
- âœ… SSE connection latency: <200ms
- âœ… Token counting: <2ms per text

**Cost:**
- âœ… Average debate: $0.08-$0.11
- âœ… Warning system: 3 tiers ($0.50, $1.00, $2.00)
- âœ… User control: Configurable thresholds

**Reliability:**
- âœ… Isolated failures: Continue with remaining debaters
- âœ… Automatic reconnection: Exponential backoff
- âœ… Context preservation: Resumption with Last-Event-ID

**User Experience:**
- âœ… Real-time streaming: Sub-second latency
- âœ… Synchronized display: 100ms buffer window
- âœ… Clear cost feedback: Real-time updates

---

## Next Steps

1. **Review Research** - Team reviews all four documents
2. **Architecture Sign-off** - Approve XState + FastAPI + SSE architecture
3. **Begin Phase 2A** - Implement core debate engine
4. **Iterative Development** - Build â†’ Test â†’ Refine
5. **Integration Testing** - Real LLM testing with all providers

---

## Sources

All research documents include comprehensive source lists covering:
- Official documentation (XState, SSE, provider APIs)
- Production examples and case studies
- Academic research on multi-agent systems
- Performance benchmarks and optimization guides

See individual documents for detailed citations.

---

**Research Status:** âœ… **COMPLETE** - Ready for Phase 2 implementation

**Estimated Development Time:** 5-6 weeks (3 phases)

**Confidence Level:** Very High (9/10) - All technical approaches validated with production examples
